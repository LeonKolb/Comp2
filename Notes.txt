# redundant
def find_local_maxima_timepoints(dat_file_path):
    try:
        # Load data from the .dat file using numpy
        data = np.loadtxt(dat_file_path)

        # Extract timepoints and voltage intensities
        timepoints = data[:, 0]
        voltage_intensities = data[:, 1]

        # Find local maxima indices
        maxima_indices = [i for i in range(1, len(voltage_intensities)-1) if voltage_intensities[i] > voltage_intensities[i-1] and voltage_intensities[i] > voltage_intensities[i+1]]

        # Get the timepoints corresponding to the local maxima
        maxima_timepoints = timepoints[maxima_indices]

        return maxima_timepoints

    except FileNotFoundError:
        print(f"File '{dat_file_path}' not found.")
        return None
    
# Example usage:
dat_file_path = './Resources/data/stimuli/gaussModality_co200.dat'  # Replace with the actual path to your .dat file

maxima_timepoints_result = find_local_maxima_timepoints(dat_file_path)

if maxima_timepoints_result is not None and len(maxima_timepoints_result) > 0:
    # Use a custom format to display timepoints without scientific notation
    formatted_timepoints = ["{:.2f}".format(tp) for tp in maxima_timepoints_result]
    print(f"Timepoints corresponding to local maxima: {formatted_timepoints} ({len(formatted_timepoints)} total)")

    # Optional: Plot the data with local maxima marked
    data = np.loadtxt(dat_file_path)
    plt.plot(data[:, 0], data[:, 1], label='Voltage Intensity')
    plt.scatter(maxima_timepoints_result, data[:, 1][np.searchsorted(data[:, 0], maxima_timepoints_result)], color='red', label='Local Maxima')
    plt.xlabel('Timepoints')
    plt.ylabel('Voltage Intensity')
    plt.legend()
    plt.xlim(-.5e5, 1.05e6)
    plt.show()

else:
    print("No local maxima found.")





import numpy as np

def find_local_maxima(dat_file_path):
    try:
        data = np.loadtxt(dat_file_path)

        # Extract timepoints and voltage intensities
        timepoints = data[:, 0]
        voltage_intensities = data[:, 1]

        # Initialize boolean array for local maxima
        is_local_maxima = np.full_like(voltage_intensities, False, dtype=bool)

        # Find local maxima indices
        for i in range(1, len(voltage_intensities) - 1):
            if voltage_intensities[i] > voltage_intensities[i - 1] and voltage_intensities[i] > voltage_intensities[i + 1]:
                is_local_maxima[i] = True

        maxima_timepoints = timepoints[is_local_maxima]

        # format timepoints
        formatted_timepoints = ["{:.2f}".format(tp) for tp in maxima_timepoints]

        return is_local_maxima, formatted_timepoints

    except FileNotFoundError:
        print(f"File '{dat_file_path}' not found.")
        return None




# Example usage:
dat_file_path = './Resources/data/stimuli/gaussModality_co200.dat' 

local_maxima_result, maxima_timepoints_result = find_local_maxima(dat_file_path)

print("Boolean array for local maxima:", local_maxima_result)
print("Timepoints corresponding to local maxima:", maxima_timepoints_result)




def firing_prob(spikes, coherence, minHz, maxHz, dat): #dat ist bspw. ./03-01-16-ab/03-01-16-ab_sig1_spikes.dat

    r=np.arange(minHz,maxHz,)

    with open(path+dat, 'r') as file:
        for line in file:
            if spikes == True: 
                mean_rate = findrate(dat) 
            elif spikes == False:
                mean_rate = 0
    
    std = 10. + 2/coherence
    
    p = 1./(np.sqrt(2.*np.pi)*std)*np.exp(-(r - mean_rate)**2/(2.*std**2))
    p = p/np.sum(p)
    return r, p



def min_max_scaling(data):
    min_val = np.min(data)
    max_val = np.max(data)
    scaled_data = (data - min_val) / (max_val - min_val)
    return scaled_data


#scale to cutoff freq?
rate_1 = min_max_scaling(rate_1)
rate_2 = min_max_scaling(rate_2)

print(rate_1)
print(rate_2)



def z_score_normalization(data):
    mean_val = np.mean(data)
    std_dev = np.std(data)
    normalized_data = (data - mean_val) / std_dev
    return normalized_data

# Example usage:
firing_rates = np.array([10, 15, 12, 8, 20])
normalized_firing_rates = z_score_normalization(firing_rates)

print("Original Firing Rates:", firing_rates)
print("Normalized Firing Rates (Z-Score Normalization):", normalized_firing_rates)


def parse_dat_to_json_old(dat_lines):
    json_data = []
    current_trial = []
    for line in dat_lines:
        if line.startswith("#"):
            continue  # Ignore lines starting with "#"
        elif line.strip() == "":
            if current_trial:
                json_data.append(current_trial)
                current_trial = []
            else:
                json_data.append([])  # Add an empty sublist
        else:
            timestamp = float(line.strip())
            current_trial.append(timestamp)

    if current_trial:
        json_data.append(current_trial)
    result=[]
    for sublist in json_data:
        if sublist == []:
            consecutive_empty_sublists += 1
            if consecutive_empty_sublists <= 1:
                result.append(sublist)
        else:
            result.append(sublist)
            consecutive_empty_sublists = 0

    return result